package github

import (
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"math/rand"
	"net/http"
	"net/url"
	"strconv"
	"strings"
	"time"

	"hajimi-king-go/internal/config"
	"hajimi-king-go/internal/logger"
	"hajimi-king-go/internal/models"
)

// GitHubSearchResult è¡¨ç¤ºGitHubæœç´¢ç»“æœ
type GitHubSearchResult struct {
	TotalCount       int               `json:"total_count"`
	IncompleteResults bool             `json:"incomplete_results"`
	Items            []GitHubSearchItem `json:"items"`
}

// GitHubSearchItem è¡¨ç¤ºGitHubæœç´¢çš„å•ä¸ªç»“æœé¡¹
type GitHubSearchItem struct {
	SHA        string           `json:"sha"`
	Path       string           `json:"path"`
	HTMLURL    string           `json:"html_url"`
	Repository GitHubRepository `json:"repository"`
}

// GitHubRepository è¡¨ç¤ºGitHubä»“åº“ä¿¡æ¯
type GitHubRepository struct {
	FullName  string `json:"full_name"`
	PushedAt  string `json:"pushed_at"`
}

// Client GitHubå®¢æˆ·ç«¯
type Client struct {
	tokens    []string
	tokenPtr  int
	client    *http.Client
}

// NewClient åˆ›å»ºGitHubå®¢æˆ·ç«¯
func NewClient(tokens []string) *Client {
	return &Client{
		tokens:   tokens,
		tokenPtr: 0,
		client:   &http.Client{Timeout: 30 * time.Second},
	}
}

// SearchForKeys æœç´¢GitHubä»£ç ä¸­çš„å¯†é’¥
func (c *Client) SearchForKeys(query string) (*models.GitHubSearchResult, error) {
	allItems := []GitHubSearchItem{}
	totalCount := 0
	expectedTotal := 0
	pagesProcessed := 0

	// ç»Ÿè®¡ä¿¡æ¯
	totalRequests := 0
	failedRequests := 0
	rateLimitHits := 0

	for page := 1; page <= 10; page++ {
		var pageResult *GitHubSearchResult
		pageSuccess := false

		for attempt := 1; attempt <= 5; attempt++ {
			currentToken := c.nextToken()

			headers := map[string]string{
				"Accept":     "application/vnd.github.v3+json",
				"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
			}

			if currentToken != "" {
				headers["Authorization"] = "token " + currentToken
			}

			params := url.Values{}
			params.Set("q", query)
			params.Set("per_page", "100")
			params.Set("page", strconv.Itoa(page))

			apiURL := "https://api.github.com/search/code?" + params.Encode()

			req, err := http.NewRequest("GET", apiURL, nil)
			if err != nil {
				continue
			}

			for key, value := range headers {
				req.Header.Set(key, value)
			}

			totalRequests++
			
			// è·å–éšæœºä»£ç†é…ç½®
			var proxyConfig map[string]string
			if cfg := config.GetConfig(); cfg != nil {
				proxyConfig = cfg.GetRandomProxy()
			}

			var resp *http.Response
			if proxyConfig != nil {
				// ä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚
				proxyURL := proxyConfig["http"]
				proxy, err := url.Parse(proxyURL)
				if err == nil {
					transport := &http.Transport{Proxy: http.ProxyURL(proxy)}
					client := &http.Client{Transport: transport, Timeout: 30 * time.Second}
					resp, err = client.Do(req)
				} else {
					resp, err = c.client.Do(req)
				}
			} else {
				resp, err = c.client.Do(req)
			}

			if err != nil {
				failedRequests++
				shifted := 2 << attempt
				wait := minFloat(float64(shifted)+rand.Float64(), 60)
				if attempt >= 3 {
					logger.GetLogger().Warningf("âŒ Network error after %d attempts on page %d: %v", attempt, page, err)
				}
				time.Sleep(time.Duration(wait) * time.Second)
				continue
			}
			defer resp.Body.Close()

			// æ£€æŸ¥rate limit
			rateLimitRemaining := resp.Header.Get("X-RateLimit-Remaining")
			if rateLimitRemaining != "" {
				if remaining, err := strconv.Atoi(rateLimitRemaining); err == nil && remaining < 3 {
					logger.GetLogger().Warningf("âš ï¸ Rate limit low: %d remaining, token: %s", remaining, currentToken)
				}
			}

			if resp.StatusCode == 403 || resp.StatusCode == 429 {
				rateLimitHits++
				shifted := 2 << attempt
				wait := minFloat(float64(shifted)+rand.Float64(), 60)
				if attempt >= 3 {
					logger.GetLogger().Warningf("âŒ Rate limit hit, status:%d (attempt %d/%d) - waiting %.1fs", resp.StatusCode, attempt, 5, wait)
				}
				time.Sleep(time.Duration(wait) * time.Second)
				continue
			}

			if resp.StatusCode >= 400 {
				failedRequests++
				if attempt == 5 {
					logger.GetLogger().Errorf("âŒ HTTP %d error after %d attempts on page %d", resp.StatusCode, attempt, page)
				}
				time.Sleep(time.Duration(2<<attempt) * time.Second)
				continue
			}

			body, err := io.ReadAll(resp.Body)
			if err != nil {
				failedRequests++
				continue
			}

			pageResult = &GitHubSearchResult{}
			if err := json.Unmarshal(body, pageResult); err != nil {
				failedRequests++
				continue
			}

			pageSuccess = true
			break
		}

		if !pageSuccess || pageResult == nil {
			if page == 1 {
				logger.GetLogger().Errorf("âŒ First page failed for query: %s...", query[:min(50, len(query))])
				break
			}
			continue
		}

		pagesProcessed++

		if page == 1 {
			totalCount = pageResult.TotalCount
			expectedTotal = min(totalCount, 1000)
		}

		allItems = append(allItems, pageResult.Items...)

		if expectedTotal > 0 && len(allItems) >= expectedTotal {
			break
		}

		if page < 10 {
			sleepTime := rand.Float64()*1.0 + 0.5
			logger.GetLogger().Infof("â³ Processing query: ã€%sã€‘,page %d,item count: %d,expected total: %d,total count: %d,random sleep: %.1fs",
				query, page, len(pageResult.Items), expectedTotal, totalCount, sleepTime)
			time.Sleep(time.Duration(sleepTime) * time.Second)
		}
	}

	finalCount := len(allItems)

	// æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
	if expectedTotal > 0 && finalCount < expectedTotal {
		discrepancy := expectedTotal - finalCount
		if discrepancy > expectedTotal/10 { // è¶…è¿‡10%æ•°æ®ä¸¢å¤±
			logger.GetLogger().Warningf("âš ï¸ Significant data loss: %d/%d items missing (%.1f%%)",
				discrepancy, expectedTotal, float64(discrepancy)/float64(expectedTotal)*100)
		}
	}

	// ä¸»è¦æˆåŠŸæ—¥å¿— - ä¸€æ¡æ—¥å¿—åŒ…å«æ‰€æœ‰å…³é”®ä¿¡æ¯
	logger.GetLogger().Infof("ğŸ” GitHub search complete: query:ã€%sã€‘ | page success count:%d | items count:%d/%d | total requests:%d",
		query, pagesProcessed, finalCount, expectedTotal, totalRequests)

	// è½¬æ¢ä¸ºmodels.GitHubSearchItem
	modelItems := make([]models.GitHubSearchItem, len(allItems))
	for i, item := range allItems {
		modelItems[i] = models.GitHubSearchItem{
			SHA:     item.SHA,
			Path:    item.Path,
			HTMLURL: item.HTMLURL,
			Repository: models.GitHubRepository{
				FullName: item.Repository.FullName,
				PushedAt: item.Repository.PushedAt,
			},
		}
	}

	return &models.GitHubSearchResult{
		TotalCount:       totalCount,
		IncompleteResults: finalCount < expectedTotal && expectedTotal > 0,
		Items:            modelItems,
	}, nil
}

// GetFileContent è·å–æ–‡ä»¶å†…å®¹
func (c *Client) GetFileContent(item models.GitHubSearchItem) (string, error) {
	repoFullName := item.Repository.FullName
	filePath := item.Path

	metadataURL := fmt.Sprintf("https://api.github.com/repos/%s/contents/%s", repoFullName, filePath)
	
	headers := map[string]string{
		"Accept":     "application/vnd.github.v3+json",
		"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
	}

	currentToken := c.nextToken()
	if currentToken != "" {
		headers["Authorization"] = "token " + currentToken
	}

	req, err := http.NewRequest("GET", metadataURL, nil)
	if err != nil {
		return "", err
	}

	for key, value := range headers {
		req.Header.Set(key, value)
	}

	// è·å–ä»£ç†é…ç½®
	var proxyConfig map[string]string
	if cfg := config.GetConfig(); cfg != nil {
		proxyConfig = cfg.GetRandomProxy()
	}

	var resp *http.Response
	if proxyConfig != nil {
		// ä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚
		proxyURL := proxyConfig["http"]
		proxy, err := url.Parse(proxyURL)
		if err == nil {
			transport := &http.Transport{Proxy: http.ProxyURL(proxy)}
			client := &http.Client{Transport: transport, Timeout: 30 * time.Second}
			resp, err = client.Do(req)
		} else {
			resp, err = c.client.Do(req)
		}
	} else {
		resp, err = c.client.Do(req)
	}

	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	logger.GetLogger().Infof("ğŸ” Processing file: %s", metadataURL)

	if resp.StatusCode >= 400 {
		return "", fmt.Errorf("HTTP error: %d", resp.StatusCode)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", err
	}

	var fileMetadata struct {
		Encoding   string `json:"encoding"`
		Content    string `json:"content"`
		DownloadURL string `json:"download_url"`
	}

	if err := json.Unmarshal(body, &fileMetadata); err != nil {
		return "", err
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰base64ç¼–ç çš„å†…å®¹
	if fileMetadata.Encoding == "base64" && fileMetadata.Content != "" {
		decodedContent, err := base64.StdEncoding.DecodeString(fileMetadata.Content)
		if err == nil {
			return string(decodedContent), nil
		}
		logger.GetLogger().Warningf("âš ï¸ Failed to decode base64 content: %v, falling back to download_url", err)
	}

	// å¦‚æœæ²¡æœ‰base64å†…å®¹æˆ–è§£ç å¤±è´¥ï¼Œä½¿ç”¨download_url
	if fileMetadata.DownloadURL == "" {
		return "", fmt.Errorf("no download URL found for file: %s", metadataURL)
	}

	// ä½¿ç”¨ä»£ç†è·å–æ–‡ä»¶å†…å®¹
	var downloadResp *http.Response
	if proxyConfig != nil {
		proxyURL := proxyConfig["http"]
		proxy, err := url.Parse(proxyURL)
		if err == nil {
			transport := &http.Transport{Proxy: http.ProxyURL(proxy)}
			client := &http.Client{Transport: transport, Timeout: 30 * time.Second}
			downloadResp, err = client.Get(fileMetadata.DownloadURL)
		} else {
			downloadResp, err = c.client.Get(fileMetadata.DownloadURL)
		}
	} else {
		downloadResp, err = c.client.Get(fileMetadata.DownloadURL)
	}

	if err != nil {
		return "", err
	}
	defer downloadResp.Body.Close()

	logger.GetLogger().Infof("â³ checking for keys from: %s, status: %d", fileMetadata.DownloadURL, downloadResp.StatusCode)

	if downloadResp.StatusCode >= 400 {
		return "", fmt.Errorf("download error: %d", downloadResp.StatusCode)
	}

	content, err := io.ReadAll(downloadResp.Body)
	if err != nil {
		return "", err
	}

	return string(content), nil
}

// nextToken è·å–ä¸‹ä¸€ä¸ªtoken
func (c *Client) nextToken() string {
	if len(c.tokens) == 0 {
		return ""
	}

	token := c.tokens[c.tokenPtr%len(c.tokens)]
	c.tokenPtr++
	return strings.TrimSpace(token)
}

// min è¿”å›ä¸¤ä¸ªæ•´æ•°ä¸­çš„è¾ƒå°å€¼
func minInt(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// min è¿”å›ä¸¤ä¸ªæµ®ç‚¹æ•°ä¸­çš„è¾ƒå°å€¼
func minFloat(a, b float64) float64 {
	if a < b {
		return a
	}
	return b
}