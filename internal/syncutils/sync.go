package syncutils

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"
	"sync"
	"time"

	"hajimi-king-go/internal/config"
	"hajimi-king-go/internal/logger"
)

// GroupInfo GPT Load Groupä¿¡æ¯
type GroupInfo struct {
	ID   int    `json:"id"`
	Name string `json:"name"`
}

// GroupsResponse GPT Load Groups APIå“åº”
type GroupsResponse struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    []GroupInfo `json:"data"`
}

// AddKeysResponse GPT Load Add Keys APIå“åº”
type AddKeysResponse struct {
	Code    string      `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

// SyncUtils åŒæ­¥å·¥å…·
type SyncUtils struct {
	config           *config.Config
	BalancerEnabled  bool
	balancerQueue    []string
	GPTLoadEnabled   bool
	gptLoadQueue     []string
	lastSyncTime     time.Time
	syncInterval     time.Duration
	stopChan         chan struct{}
	
	// GPT Load Group IDç¼“å­˜
	groupIDCache     map[string]int
	groupIDCacheTime map[string]time.Time
	groupIDCacheTTL  time.Duration
	cacheMutex       sync.RWMutex
}

// NewSyncUtils åˆ›å»ºåŒæ­¥å·¥å…·
func NewSyncUtils(cfg *config.Config) *SyncUtils {
	return &SyncUtils{
		config:          cfg,
		BalancerEnabled: cfg.GeminiBalancerSyncEnabled,
		balancerQueue:   []string{},
		GPTLoadEnabled:  cfg.GPTLoadSyncEnabled,
		gptLoadQueue:    []string{},
		syncInterval:    5 * time.Minute, // é»˜è®¤5åˆ†é’ŸåŒæ­¥ä¸€æ¬¡
		stopChan:        make(chan struct{}),
		
		// åˆå§‹åŒ–GPT Load Group IDç¼“å­˜
		groupIDCache:     make(map[string]int),
		groupIDCacheTime: make(map[string]time.Time),
		groupIDCacheTTL:  15 * time.Minute, // 15åˆ†é’Ÿç¼“å­˜
		cacheMutex:       sync.RWMutex{},
	}
}

// Start å¯åŠ¨åŒæ­¥æœåŠ¡
func (su *SyncUtils) Start() {
	if !su.BalancerEnabled && !su.GPTLoadEnabled {
		logger.GetLogger().Info("â„¹ï¸ No sync services enabled")
		return
	}

	logger.GetLogger().Info("ğŸ”— Starting sync services...")
	go su.syncWorker()
}

// Stop åœæ­¢åŒæ­¥æœåŠ¡
func (su *SyncUtils) Stop() {
	close(su.stopChan)
	logger.GetLogger().Info("ğŸ”š Sync services stopped")
}

// AddKeysToQueue æ·»åŠ å¯†é’¥åˆ°åŒæ­¥é˜Ÿåˆ—
func (su *SyncUtils) AddKeysToQueue(keys []string) error {
	if len(keys) == 0 {
		return nil
	}

	if su.BalancerEnabled {
		su.balancerQueue = append(su.balancerQueue, keys...)
		logger.GetLogger().Infof("ğŸ“¥ Added %d keys to balancer queue", len(keys))
	}

	if su.GPTLoadEnabled {
		su.gptLoadQueue = append(su.gptLoadQueue, keys...)
		logger.GetLogger().Infof("ğŸ“¥ Added %d keys to GPT Load queue", len(keys))
	}

	return nil
}

// syncWorker åŒæ­¥å·¥ä½œåç¨‹
func (su *SyncUtils) syncWorker() {
	ticker := time.NewTicker(su.syncInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			su.doSync()
		case <-su.stopChan:
			return
		}
	}
}

// doSync æ‰§è¡ŒåŒæ­¥æ“ä½œ
func (su *SyncUtils) doSync() {
	if len(su.balancerQueue) > 0 {
		if err := su.syncToBalancer(); err != nil {
			logger.GetLogger().Errorf("âŒ Failed to sync to balancer: %v", err)
		}
	}

	if len(su.gptLoadQueue) > 0 {
		if err := su.syncToGPTLoad(); err != nil {
			logger.GetLogger().Errorf("âŒ Failed to sync to GPT Load: %v", err)
		}
	}
}

// syncToBalancer åŒæ­¥åˆ°Gemini Balancer
func (su *SyncUtils) syncToBalancer() error {
	if len(su.balancerQueue) == 0 {
		return nil
	}

	logger.GetLogger().Infof("ğŸ”— Syncing %d keys to Gemini Balancer...", len(su.balancerQueue))

	// 1. è·å–å½“å‰é…ç½®
	configURL := su.config.GeminiBalancerURL + "/api/config"
	
	client := &http.Client{
		Timeout: 30 * time.Second,
	}
	
	req, err := http.NewRequest("GET", configURL, nil)
	if err != nil {
		return fmt.Errorf("failed to create config request: %v", err)
	}
	
	// è®¾ç½®è®¤è¯å¤´ - ä½¿ç”¨Cookieè®¤è¯
	req.Header.Set("Cookie", "auth_token="+su.config.GeminiBalancerAuth)
	req.Header.Set("User-Agent", "HajimiKing/1.0")
	
	logger.GetLogger().Infof("ğŸ“¥ Fetching current config from: %s", configURL)
	
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("failed to get config: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		return fmt.Errorf("failed to get config: HTTP %d", resp.StatusCode)
	}
	
	// è§£æé…ç½®å“åº”
	var configData map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&configData); err != nil {
		return fmt.Errorf("failed to decode config response: %v", err)
	}
	
	// 2. è·å–å½“å‰çš„API_KEYSæ•°ç»„
	currentAPIKeys, ok := configData["API_KEYS"].([]interface{})
	if !ok {
		currentAPIKeys = []interface{}{}
	}
	
	// 3. åˆå¹¶æ–°keysï¼ˆå»é‡ï¼‰
	existingKeysSet := make(map[string]bool)
	for _, key := range currentAPIKeys {
		if keyStr, ok := key.(string); ok {
			existingKeysSet[keyStr] = true
		}
	}
	
	newAddKeysSet := make(map[string]bool)
	for _, key := range su.balancerQueue {
		if !existingKeysSet[key] {
			existingKeysSet[key] = true
			newAddKeysSet[key] = true
		}
	}
	
	if len(newAddKeysSet) == 0 {
		logger.GetLogger().Infof("â„¹ï¸ All %d key(s) already exist in balancer", len(su.balancerQueue))
		// æ¸…ç©ºé˜Ÿåˆ—
		su.balancerQueue = []string{}
		return nil
	}
	
	// 4. æ›´æ–°é…ç½®ä¸­çš„API_KEYS
	var updatedKeys []string
	for key := range existingKeysSet {
		updatedKeys = append(updatedKeys, key)
	}
	configData["API_KEYS"] = updatedKeys
	
	logger.GetLogger().Infof("ğŸ“ Updating gemini balancer config with %d new key(s)...", len(newAddKeysSet))
	
	// 5. å‘é€æ›´æ–°åçš„é…ç½®åˆ°æœåŠ¡å™¨
	jsonData, err := json.Marshal(configData)
	if err != nil {
		return fmt.Errorf("failed to marshal config data: %v", err)
	}
	
	req, err = http.NewRequest("PUT", configURL, bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("failed to create update request: %v", err)
	}
	
	// è®¾ç½®è®¤è¯å¤´
	req.Header.Set("Cookie", "auth_token="+su.config.GeminiBalancerAuth)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("User-Agent", "HajimiKing/1.0")
	
	resp, err = client.Do(req)
	if err != nil {
		return fmt.Errorf("failed to update config: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		return fmt.Errorf("failed to update config: HTTP %d", resp.StatusCode)
	}
	
	// 6. éªŒè¯æ˜¯å¦æ·»åŠ æˆåŠŸ
	var updatedConfig map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&updatedConfig); err != nil {
		return fmt.Errorf("failed to decode update response: %v", err)
	}
	
	updatedAPIKeys, ok := updatedConfig["API_KEYS"].([]interface{})
	if !ok {
		return fmt.Errorf("invalid API_KEYS format in response")
	}
	
	updatedKeysSet := make(map[string]bool)
	for _, key := range updatedAPIKeys {
		if keyStr, ok := key.(string); ok {
			updatedKeysSet[keyStr] = true
		}
	}
	
	var failedToAdd []string
	for key := range newAddKeysSet {
		if !updatedKeysSet[key] {
			failedToAdd = append(failedToAdd, key)
		}
	}
	
	if len(failedToAdd) > 0 {
		return fmt.Errorf("failed to add %d keys", len(failedToAdd))
	}
	
	logger.GetLogger().Infof("âœ… All %d new key(s) successfully added to balancer", len(newAddKeysSet))
	
	// æ¸…ç©ºé˜Ÿåˆ—
	su.balancerQueue = []string{}
	return nil
}

// getGPTLoadGroupID è·å–GPT Load Group IDï¼Œå¸¦ç¼“å­˜åŠŸèƒ½
func (su *SyncUtils) getGPTLoadGroupID(groupName string) (int, error) {
	// æ£€æŸ¥ç¼“å­˜
	su.cacheMutex.RLock()
	cachedID, hasCache := su.groupIDCache[groupName]
	cacheTime, hasTime := su.groupIDCacheTime[groupName]
	su.cacheMutex.RUnlock()
	
	if hasCache && hasTime && time.Since(cacheTime) < su.groupIDCacheTTL {
		logger.GetLogger().Infof("ğŸ“‹ Using cached group ID for '%s': %d", groupName, cachedID)
		return cachedID, nil
	}
	
	// ç¼“å­˜ä¸å­˜åœ¨æˆ–è¿‡æœŸï¼Œé‡æ–°è·å–
	groupsURL := su.config.GPTLoadURL + "/api/groups"
	
	client := &http.Client{
		Timeout: 30 * time.Second,
	}
	
	req, err := http.NewRequest("GET", groupsURL, nil)
	if err != nil {
		return 0, fmt.Errorf("failed to create request: %v", err)
	}
	
	// è®¾ç½®è®¤è¯å¤´
	req.Header.Set("Authorization", "Bearer "+su.config.GPTLoadAuth)
	req.Header.Set("User-Agent", "HajimiKing/1.0")
	
	resp, err := client.Do(req)
	if err != nil {
		return 0, fmt.Errorf("failed to get groups: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		return 0, fmt.Errorf("groups API returned status code: %d", resp.StatusCode)
	}
	
	var groupsResp GroupsResponse
	if err := json.NewDecoder(resp.Body).Decode(&groupsResp); err != nil {
		return 0, fmt.Errorf("failed to decode groups response: %v", err)
	}
	
	if groupsResp.Code != 0 {
		return 0, fmt.Errorf("groups API returned error: %s", groupsResp.Message)
	}
	
	// æŸ¥æ‰¾æŒ‡å®šgroupçš„ID
	for _, group := range groupsResp.Data {
		if group.Name == groupName {
			// æ›´æ–°ç¼“å­˜
			su.cacheMutex.Lock()
			su.groupIDCache[groupName] = group.ID
			su.groupIDCacheTime[groupName] = time.Now()
			su.cacheMutex.Unlock()
			
			logger.GetLogger().Infof("âœ… Found and cached group '%s' with ID: %d", groupName, group.ID)
			return group.ID, nil
		}
	}
	
	return 0, fmt.Errorf("group '%s' not found", groupName)
}

// syncToGPTLoad åŒæ­¥åˆ°GPT Load
func (su *SyncUtils) syncToGPTLoad() error {
	if len(su.gptLoadQueue) == 0 {
		return nil
	}

	logger.GetLogger().Infof("ğŸ”— Syncing %d keys to GPT Load...", len(su.gptLoadQueue))

	// è§£æç»„å
	groups := strings.Split(su.config.GPTLoadGroupName, ",")
	for i, group := range groups {
		groups[i] = strings.TrimSpace(group)
	}

	// ä¸ºæ¯ä¸ªç»„å¹¶å‘å‘é€å¯†é’¥
	var wg sync.WaitGroup
	failedGroupsChan := make(chan string, len(groups))

	for _, group := range groups {
		if group == "" {
			continue
		}
		wg.Add(1)
		go func(g string) {
			defer wg.Done()
			
			logger.GetLogger().Infof("ğŸ“ Processing group: %s", g)
			
			// 1. è·å–group ID
			groupID, err := su.getGPTLoadGroupID(g)
			if err != nil {
				logger.GetLogger().Errorf("âŒ Failed to get group ID for '%s': %v", g, err)
				failedGroupsChan <- g
				return
			}
			
			// 2. å‘é€keysåˆ°æŒ‡å®šgroup
			addKeysURL := su.config.GPTLoadURL + "/api/keys/add-async"
			keysText := strings.Join(su.gptLoadQueue, ",")
			
			data := map[string]interface{}{
				"group_id":   groupID,
				"keys_text":  keysText,
			}
			
			jsonData, err := json.Marshal(data)
			if err != nil {
				logger.GetLogger().Errorf("âŒ Failed to marshal GPT Load data for group '%s': %v", g, err)
				failedGroupsChan <- g
				return
			}
			
			client := &http.Client{
				Timeout: 60 * time.Second,
			}
			
			req, err := http.NewRequest("POST", addKeysURL, bytes.NewBuffer(jsonData))
			if err != nil {
				logger.GetLogger().Errorf("âŒ Failed to create request for group '%s': %v", g, err)
				failedGroupsChan <- g
				return
			}
			
			// è®¾ç½®è®¤è¯å¤´
			req.Header.Set("Authorization", "Bearer "+su.config.GPTLoadAuth)
			req.Header.Set("Content-Type", "application/json")
			req.Header.Set("User-Agent", "HajimiKing/1.0")
			
			resp, err := client.Do(req)
			if err != nil {
				logger.GetLogger().Errorf("âŒ Failed to send request to GPT Load for group '%s': %v", g, err)
				failedGroupsChan <- g
				return
			}
			defer resp.Body.Close()
			
			if resp.StatusCode != 200 {
				logger.GetLogger().Errorf("âŒ GPT Load returned status code %d for group '%s'", resp.StatusCode, g)
				failedGroupsChan <- g
				return
			}
			
			var addResp AddKeysResponse
			if err := json.NewDecoder(resp.Body).Decode(&addResp); err != nil {
				logger.GetLogger().Errorf("âŒ Failed to decode add keys response for group '%s': %v", g, err)
				failedGroupsChan <- g
				return
			}
			
			// æ£€æŸ¥å“åº”çŠ¶æ€
			if addResp.Code != "0" && addResp.Code != "success" {
				logger.GetLogger().Errorf("âŒ Add keys API returned error for group '%s': %s", g, addResp.Message)
				failedGroupsChan <- g
				return
			}
			
			// æ£€æŸ¥ä»»åŠ¡æ•°æ®
			if taskData, ok := addResp.Data.(map[string]interface{}); ok {
				taskType := taskData["task_type"]
				isRunning := taskData["is_running"]
				total := taskData["total"]
				responseGroupName := taskData["group_name"]
				
				logger.GetLogger().Infof("âœ… Keys addition task started successfully for group '%s':", g)
				logger.GetLogger().Infof("   Task Type: %v", taskType)
				logger.GetLogger().Infof("   Is Running: %v", isRunning)
				logger.GetLogger().Infof("   Total Keys: %v", total)
				logger.GetLogger().Infof("   Group Name: %v", responseGroupName)
			}
		}(group)
	}

	wg.Wait()
	close(failedGroupsChan)

	var failedGroups []string
	for g := range failedGroupsChan {
		failedGroups = append(failedGroups, g)
	}
	
	// æ ¹æ®ç»“æœè¿”å›çŠ¶æ€
	if len(failedGroups) == 0 {
		logger.GetLogger().Infof("âœ… Successfully sent keys to all %d group(s)", len(groups))
		// æ¸…ç©ºé˜Ÿåˆ—
		su.gptLoadQueue = []string{}
		return nil
	} else {
		logger.GetLogger().Errorf("âŒ Failed to send keys to %d group(s): %s", len(failedGroups), strings.Join(failedGroups, ", "))
		return fmt.Errorf("failed to send keys to %d groups", len(failedGroups))
	}
}

// GetQueueStatus è·å–é˜Ÿåˆ—çŠ¶æ€
func (su *SyncUtils) GetQueueStatus() (int, int) {
	return len(su.balancerQueue), len(su.gptLoadQueue)
}

// SetSyncInterval è®¾ç½®åŒæ­¥é—´éš”
func (su *SyncUtils) SetSyncInterval(interval time.Duration) {
	su.syncInterval = interval
	logger.GetLogger().Infof("ğŸ• Sync interval set to %v", interval)
}